{
    "docs": [
        {
            "location": "/", 
            "text": ".steps-title { float: left; width: 25%; margin-bottom: 20px; }\n.steps-title > p { font-weight: bold; font-size: 150%; }\n.steps-content { float: left; width: 74%; margin-bottom: 20px; }\n.clear { clear: both; }\n.center { text-align: center; }\n.social { text-align: center; }\n\n\n\n\nWelcome to Datapalooza!\n\n\nOut next Datapalooza is in Austin, TX on April 28th!\n\n\nRegister for free now!\n\n\nDatapalooza\n is an immersive experience for the data science community to learn new skills, tools and technologies.\n\n\nLearn\n\n\nTake the \nSpark Fundamentals\n course and the\n\nData Scientist Workbench Tutorial\n\non Big Data University.\n\n\nRun Spark\n\n\nLogin into your \nData Scientist Workbench\n\naccount to have a Spark runtime immediately available for you!", 
            "title": "First Steps"
        }, 
        {
            "location": "/#welcome-to-datapalooza", 
            "text": "Out next Datapalooza is in Austin, TX on April 28th!  Register for free now!  Datapalooza  is an immersive experience for the data science community to learn new skills, tools and technologies.", 
            "title": "Welcome to Datapalooza!"
        }, 
        {
            "location": "/#learn", 
            "text": "Take the  Spark Fundamentals  course and the Data Scientist Workbench Tutorial \non Big Data University.", 
            "title": "Learn"
        }, 
        {
            "location": "/#run-spark", 
            "text": "Login into your  Data Scientist Workbench \naccount to have a Spark runtime immediately available for you!", 
            "title": "Run Spark"
        }, 
        {
            "location": "/introduction/slack/", 
            "text": "Slack\n is an\nawesome platform for team communication and it's our tool of\nchoice for this hackathon. All the communication will flow\nthrough Slack!\n\n\nYou have been sent an invitation for this hackathon's\n\nSlack team\n.\nIn case you haven't received it, please find an organizer.\n\n\nYou can use Slack from your Web browser, but we\n\nstrongly recommend\n that you the native apps:\n\n\n\n\nMac OS\n\n\nWindows\n\n\niOS\n\n\nAndroid", 
            "title": "Slack"
        }, 
        {
            "location": "/introduction/resources/", 
            "text": "Free courses on \nBig Data University\n:\n\n\n\n\n\n\nSpark Fundamentals\n\n\n\n\n\n\nBig Data Fundamentals\n\n\n\n\n\n\nHadoop Fundamentals I\n\n\n\n\n\n\nMoving Data into Hadoop\n\n\n\n\n\n\nBig Data Analytics - Demos", 
            "title": "Resources"
        }, 
        {
            "location": "/introduction/sessions/", 
            "text": "Seattle\n\n\n\n\n\n\n\n\nSession\n\n\nMaterials\n\n\n\n\n\n\n\n\n\n\nBuilding Scalable Data Pipelines\n\n\nSlides\n\n\n\n\n\n\nData to Action with IBM Bluemix\n\n\nSlides\n\n\n\n\n\n\nData Processing in Data Science\n\n\nSlides\n\n\n\n\n\n\nEssential Economics for Data Scientists\n\n\nSlides\n\n\n\n\n\n\nFeature Engineering for Predictive Modeling\n\n\nSlides\n\n\n\n\n\n\nIntro to Anaconda Cluster for Scientific Workflows\n\n\nSlides\n\n\n\n\n\n\nIntro to IBM Cloud Data Services and Apache Spark\n\n\nSlides\n\n\n\n\n\n\nIntro to Python for Data Analysis\n\n\nSlides\n\n\n\n\n\n\nInvestigating Data Scientists\n\n\nSlides\n\n\n\n\n\n\nMathematics for Data Science\n\n\nSlides\n\n\n\n\n\n\nSemantic Analysis of Natural Language with Python\n\n\nCode\n\n\n\n\n\n\nSpark and Scala: Coevolving Eco Systems for Data\n\n\nSlides\n\n\n\n\n\n\nStreaming Telematics Solution for Vehicle Failures\n\n\nSlides\n\n\n\n\n\n\nTune Up Your Data Science Process\n\n\nSlides\n\n\n\n\n\n\nWord2Vec with Twitter Data\n\n\nSlides\n\n\n\n\n\n\n\n\nSan Francisco\n\n\n\n\n\n\n\n\nSession\n\n\nMaterials\n\n\n\n\n\n\n\n\n\n\nCaltrain Rider: A Complete Data Product\n\n\nhttps://github.com/silicon-valley-data-science/\n\n\n\n\n\n\nWhos in the News: Build a Quality web app with minimal code\n\n\nhttps://github.com/AlchemyAPI/whos-in-the-news\n\n\n\n\n\n\nBuilding a Word2Vec Model with Twitter Data\n\n\nhttps://github.com/castanan/w2v\n\n\n\n\n\n\nSpark Streaming application with Twitter and Watson\n\n\nhttps://github.com/ibm-cds-labs/spark.samples/tree/master/streaming-twitter\n\n\n\n\n\n\nMurv Part 1: Introduction to Muvr and lab around wearable and mobile\n\n\nhttps://github.com/muvr\n\n\n\n\n\n\nCustomer Relationship Prediction with Machine Learning Ensembles\n\n\nhttps://github.com/Jay-Oh-eN/data-scientists-guide-apache-spark\n\n\n\n\n\n\nMurv Part 2: Finish Wearable and mobile lab and move into a lab on training a model\n\n\nhttps://github.com/muvr\n\n\n\n\n\n\nMurv Part 3: Final lab on paralleling computation and conclusion\n\n\nhttps://github.com/muvr\n\n\n\n\n\n\nNLP Enriched Product Review\n\n\nhttps://github.com/AlchemyAPI/reviewRecipe\n\n\n\n\n\n\nSearch by Selfie: a Spark Facial Recognition Algorithm\n\n\nhttps://github.com/hackspark/SearchBySelfie/blob/master/photoSearchApp.ipynb", 
            "title": "Session Materials"
        }, 
        {
            "location": "/introduction/sessions/#seattle", 
            "text": "Session  Materials      Building Scalable Data Pipelines  Slides    Data to Action with IBM Bluemix  Slides    Data Processing in Data Science  Slides    Essential Economics for Data Scientists  Slides    Feature Engineering for Predictive Modeling  Slides    Intro to Anaconda Cluster for Scientific Workflows  Slides    Intro to IBM Cloud Data Services and Apache Spark  Slides    Intro to Python for Data Analysis  Slides    Investigating Data Scientists  Slides    Mathematics for Data Science  Slides    Semantic Analysis of Natural Language with Python  Code    Spark and Scala: Coevolving Eco Systems for Data  Slides    Streaming Telematics Solution for Vehicle Failures  Slides    Tune Up Your Data Science Process  Slides    Word2Vec with Twitter Data  Slides", 
            "title": "Seattle"
        }, 
        {
            "location": "/introduction/sessions/#san-francisco", 
            "text": "Session  Materials      Caltrain Rider: A Complete Data Product  https://github.com/silicon-valley-data-science/    Whos in the News: Build a Quality web app with minimal code  https://github.com/AlchemyAPI/whos-in-the-news    Building a Word2Vec Model with Twitter Data  https://github.com/castanan/w2v    Spark Streaming application with Twitter and Watson  https://github.com/ibm-cds-labs/spark.samples/tree/master/streaming-twitter    Murv Part 1: Introduction to Muvr and lab around wearable and mobile  https://github.com/muvr    Customer Relationship Prediction with Machine Learning Ensembles  https://github.com/Jay-Oh-eN/data-scientists-guide-apache-spark    Murv Part 2: Finish Wearable and mobile lab and move into a lab on training a model  https://github.com/muvr    Murv Part 3: Final lab on paralleling computation and conclusion  https://github.com/muvr    NLP Enriched Product Review  https://github.com/AlchemyAPI/reviewRecipe    Search by Selfie: a Spark Facial Recognition Algorithm  https://github.com/hackspark/SearchBySelfie/blob/master/photoSearchApp.ipynb", 
            "title": "San Francisco"
        }, 
        {
            "location": "/challenges/seattle-day-1/", 
            "text": "Using \nData Scientist Workbench\n, determine the top 5\nwinning teams and their average scores during the 2015-6 \nregular\n season. You\nshould also determine the best and worst teams for turnovers.\n\n\nJupyter\n\n\nGet the exercise and the data by importing the Jupyter notebook below.\n\n\nhttps://share.datascientistworkbench.com/#/api/v1/workbench/10.114.214.147/shares/L00Ijjdc2x0y24m/Challenge_1.ipynb\n\n\nCopy the url above and\n\nimport it\n\nin your workbench by pasting it in the appropriate box.\n\n\n\n\n\n\n\n\nZeppelin\n\n\nIf you prefer, you can use Zeppelin instead of Jupyter.\n\n\n\n\nZeppelin notebook for Day 1 Challenge\n\n\n\n\nTo import into Zeppelin, click on \nImport Note\n on the Zeppelin front page.\n\n\nSolution\n\n\nOfficial solution for the Day 1 Challenge:\n\n\nhttps://share.datascientistworkbench.com/#/api/v1/workbench/10.114.214.147/shares/eVtKpk0GwENtVuJ/SOLUTION_Challenge_1.ipynb\n\n\nWinning Entry\n\n\nHere is \nJayson Stemmler\n's\nwinning entry:\n\n\nhttps://share.datascientistworkbench.com/#/api/v1/workbench/10.114.214.147/shares/SYvuu7cwJJgoJ8q/Challenge_1_SEA_JaysonStemmler.ipynb", 
            "title": "Seattle Day 1 Challenge"
        }, 
        {
            "location": "/challenges/seattle-day-1/#jupyter", 
            "text": "Get the exercise and the data by importing the Jupyter notebook below.  https://share.datascientistworkbench.com/#/api/v1/workbench/10.114.214.147/shares/L00Ijjdc2x0y24m/Challenge_1.ipynb  Copy the url above and import it \nin your workbench by pasting it in the appropriate box.", 
            "title": "Jupyter"
        }, 
        {
            "location": "/challenges/seattle-day-1/#zeppelin", 
            "text": "If you prefer, you can use Zeppelin instead of Jupyter.   Zeppelin notebook for Day 1 Challenge   To import into Zeppelin, click on  Import Note  on the Zeppelin front page.", 
            "title": "Zeppelin"
        }, 
        {
            "location": "/challenges/seattle-day-1/#solution", 
            "text": "Official solution for the Day 1 Challenge:  https://share.datascientistworkbench.com/#/api/v1/workbench/10.114.214.147/shares/eVtKpk0GwENtVuJ/SOLUTION_Challenge_1.ipynb", 
            "title": "Solution"
        }, 
        {
            "location": "/challenges/seattle-day-1/#winning-entry", 
            "text": "Here is  Jayson Stemmler 's\nwinning entry:  https://share.datascientistworkbench.com/#/api/v1/workbench/10.114.214.147/shares/SYvuu7cwJJgoJ8q/Challenge_1_SEA_JaysonStemmler.ipynb", 
            "title": "Winning Entry"
        }, 
        {
            "location": "/challenges/seattle-day-2/", 
            "text": "We have a few tweets gathered the morning after the last Republican debate.\nDetermine the count of positive and negative tweets that contain the keyword\n\u201cTrump\u201d.\n\n\n\n\nHint:\n To get the solution we used the\n\nNatural Language Toolkit\n\n\n\n\nJupyter\n\n\nGet started with challenge in \nData Scientist Workbench\n\nusing this Jupyter notebook:\n\n\nhttps://share.datascientistworkbench.com/#/api/v1/workbench/10.114.214.147/shares/Zdc0xlFQbSbvKQm/Challenge_2.ipynb\n\n\nCopy the url above and\n\nimport it\n\nin your workbench by pasting it in the appropriate box.\n\n\n\n\n\n\n\n\nSolution\n\n\nOfficial solution for the Day 2 Challenge:\n\n\nhttps://share.datascientistworkbench.com/#/api/v1/workbench/10.114.214.147/shares/S24DfpW9Z8zXzZC/SOLUTION_Challenge_2.ipynb\n\n\nWinning Entry\n\n\nHere is the winning entry:\n\n\nhttps://share.datascientistworkbench.com/#/api/v1/workbench/10.114.214.147/shares/6hPnK3p8zY6zlMs/alexsher.ipynb", 
            "title": "Seattle Day 2 Challenge"
        }, 
        {
            "location": "/challenges/seattle-day-2/#jupyter", 
            "text": "Get started with challenge in  Data Scientist Workbench \nusing this Jupyter notebook:  https://share.datascientistworkbench.com/#/api/v1/workbench/10.114.214.147/shares/Zdc0xlFQbSbvKQm/Challenge_2.ipynb  Copy the url above and import it \nin your workbench by pasting it in the appropriate box.", 
            "title": "Jupyter"
        }, 
        {
            "location": "/challenges/seattle-day-2/#solution", 
            "text": "Official solution for the Day 2 Challenge:  https://share.datascientistworkbench.com/#/api/v1/workbench/10.114.214.147/shares/S24DfpW9Z8zXzZC/SOLUTION_Challenge_2.ipynb", 
            "title": "Solution"
        }, 
        {
            "location": "/challenges/seattle-day-2/#winning-entry", 
            "text": "Here is the winning entry:  https://share.datascientistworkbench.com/#/api/v1/workbench/10.114.214.147/shares/6hPnK3p8zY6zlMs/alexsher.ipynb", 
            "title": "Winning Entry"
        }, 
        {
            "location": "/challenges/seattle-day-3/", 
            "text": "Using data science techniques, identify the\ngreatest set of factors (age, sex, demographic, status, cabin location, etc.)\nthat had significant impact on survival probability for passengers of the\nTitanic.\n\n\nShow how you came to your conclusion.\n\n\nJupyter\n\n\nGet started with challenge in \nData Scientist Workbench\n\nusing this Jupyter notebook:\n\n\nhttps://share.datascientistworkbench.com/#/api/v1/workbench/10.114.214.147/shares/Lq860KgLkVZ0rKB/Challenge_3.ipynb\n\n\nCopy the url above and\n\nimport it\n\nin your workbench by pasting it in the appropriate box.", 
            "title": "Seattle Day 3 Challenge"
        }, 
        {
            "location": "/challenges/seattle-day-3/#jupyter", 
            "text": "Get started with challenge in  Data Scientist Workbench \nusing this Jupyter notebook:  https://share.datascientistworkbench.com/#/api/v1/workbench/10.114.214.147/shares/Lq860KgLkVZ0rKB/Challenge_3.ipynb  Copy the url above and import it \nin your workbench by pasting it in the appropriate box.", 
            "title": "Jupyter"
        }, 
        {
            "location": "/environment/dswb/", 
            "text": "Overview\n\n\nData Scientist Workbench aims to be your one-stop shop for\ndata science tools. At this time, it includes Jupyter notebooks and Zeppelin notebooks enabled with Spark integration, as well as R Studio IDE and OpenRefine. You can use notebooks to develop and run data science projects, as well visualize, document and present your analysis.\n\n\n\n\n\n\n\n\nFor more information, take the \nData Scientist Workbench Tutorial\n on Big Data University.\n\n\nRequesting your own Data Scientist Workbench\n\n\nGo to \nData Scientist Workbench\n and click the big blue button. After completing the registration, you will receive an e-mail with instructions.\n\n\nHello World\n\n\nTo get a feel of how the Data Scientist Notebooks work with Scala and Spark, follow the steps below to load a \"Hello World\" notebook along with its sample data.\n\n\n\n\n\n\n\nGo to \nData Scientist Workbench\n and click the \nMy Notebooks\n menu.\n\n\n\n\nUse the search bar to import the following file and notebook.\n    \n\n    \n\n    \n\n    \n\n\n\n\n\n\nNotebook:\n  \nhttps://share.knowledgeanyhow.org/#/api/v1/workbench/10.114.214.68/shares/sHbSUP0luy1xE2q/Scala%20and%20Spark%20in%2015%20minutes.ipynb\n\n\n\n\n\n\nData:\n\nhttps://share.knowledgeanyhow.org/#/api/v1/workbench/10.114.214.68/shares/t9LwxWg0EkWKMYX/2015.csv\n\n\n\n\n\n\n\n\n\n\nFollow the notebook!\n    \n\n    \n\n    \n\n    \n\n\n\n\n\n\nFor more details on sharing data and notebooks, check \nthis guide\n.", 
            "title": "Data Scientist Workbench"
        }, 
        {
            "location": "/environment/dswb/#overview", 
            "text": "Data Scientist Workbench aims to be your one-stop shop for\ndata science tools. At this time, it includes Jupyter notebooks and Zeppelin notebooks enabled with Spark integration, as well as R Studio IDE and OpenRefine. You can use notebooks to develop and run data science projects, as well visualize, document and present your analysis.     For more information, take the  Data Scientist Workbench Tutorial  on Big Data University.", 
            "title": "Overview"
        }, 
        {
            "location": "/environment/dswb/#requesting-your-own-data-scientist-workbench", 
            "text": "Go to  Data Scientist Workbench  and click the big blue button. After completing the registration, you will receive an e-mail with instructions.", 
            "title": "Requesting your own Data Scientist Workbench"
        }, 
        {
            "location": "/environment/dswb/#hello-world", 
            "text": "To get a feel of how the Data Scientist Notebooks work with Scala and Spark, follow the steps below to load a \"Hello World\" notebook along with its sample data.    Go to  Data Scientist Workbench  and click the  My Notebooks  menu.   Use the search bar to import the following file and notebook.\n     \n     \n     \n        Notebook:\n   https://share.knowledgeanyhow.org/#/api/v1/workbench/10.114.214.68/shares/sHbSUP0luy1xE2q/Scala%20and%20Spark%20in%2015%20minutes.ipynb    Data: https://share.knowledgeanyhow.org/#/api/v1/workbench/10.114.214.68/shares/t9LwxWg0EkWKMYX/2015.csv      Follow the notebook!\n     \n     \n     \n        For more details on sharing data and notebooks, check  this guide .", 
            "title": "Hello World"
        }, 
        {
            "location": "/environment/download-sample-data/", 
            "text": "Sample Data - San Francisco\n\n\nWe are providing an example data set to get you started, but we encourage you to use use your own. You can download it in the link below.\n\n\nhttp://bit.ly/SFHackData\n\n\nNext, you'll probably want to extract the \nzip\n file and \nupload the \ncsv\n files to your workbench\n.", 
            "title": "Download Sample Data"
        }, 
        {
            "location": "/environment/download-sample-data/#sample-data-san-francisco", 
            "text": "We are providing an example data set to get you started, but we encourage you to use use your own. You can download it in the link below.  http://bit.ly/SFHackData  Next, you'll probably want to extract the  zip  file and  upload the  csv  files to your workbench .", 
            "title": "Sample Data - San Francisco"
        }, 
        {
            "location": "/howtos/analyzing-weather-data/", 
            "text": "Go to \nData Scientist Workbench\n and click the \nMy Notebooks\n menu.\n\n\n\n\nUse the search bar to import the following notebooks.\n    \n\n    \n\n    \n\n    \n\n\n\n\n\n\nWeather Data Preparation:\n  \nhttps://share.knowledgeanyhow.org/#/api/v1/workbench/10.114.214.68/shares/L9ftHk00qCVG8qL/Weather%20Data%20Preparation%20v2.ipynb\n\n\n\n\n\n\nWeather Data Analysis and Visualization:\n  \nhttps://share.knowledgeanyhow.org/#/api/v1/workbench/10.114.214.68/shares/9tDhX5RIIQLIKcB/Weather%20Data%20Analysis%20Visualization%20v2.ipynb\n\n\n\n\n\n\n\n\n\n\nYou can get the \nAPI key\n \nhere\n.\n\n\n\n\n\n\nFollow the notebooks!\n    \n\n    \n\n    \n\n    \n\n\n\n\n\n\nFor more details on sharing data and notebooks, check \nthis guide\n.", 
            "title": "Analyzing Weather Data"
        }, 
        {
            "location": "/howtos/sharing-data-notebooks/", 
            "text": "Sharing data and notebooks can be very useful for team collaboration.\n\n\nExporting Data and Notebooks\n\n\n\n\nGo to \nData Scientist Workbench\n and click the \nMy Notebooks\n menu.\n\n\nFind the file or notebook you want to share, and click the twistie (\n) to the left of it.\n\n\n\n\nClick the \nshare\n button (\n).\n    \n\n    \n\n    \n\n    \n\n\n\n\n\n\nClick the \nShow Link\n link to get the link to the shared notebook.\n\n\n\n\nSend this link to the person you're sharing the file or notebook with.\n\n\n\n\nImporting Data and Notebooks\n\n\n\n\nCopy the link of the file or notebook you want to import (from step 5 above).\n\n\nGo to \nData Scientist Workbench\n and click the \nMy Notebooks\n menu.\n\n\n\n\nPaste the link in the text field at the top right corner of the page.\n    \n\n    \n\n    \n\n    \n\n\n\n\n\n\nHit \nEnter\n to import the file or notebook.", 
            "title": "Sharing Data and Notebooks"
        }, 
        {
            "location": "/howtos/sharing-data-notebooks/#exporting-data-and-notebooks", 
            "text": "Go to  Data Scientist Workbench  and click the  My Notebooks  menu.  Find the file or notebook you want to share, and click the twistie ( ) to the left of it.   Click the  share  button ( ).\n     \n     \n     \n        Click the  Show Link  link to get the link to the shared notebook.   Send this link to the person you're sharing the file or notebook with.", 
            "title": "Exporting Data and Notebooks"
        }, 
        {
            "location": "/howtos/sharing-data-notebooks/#importing-data-and-notebooks", 
            "text": "Copy the link of the file or notebook you want to import (from step 5 above).  Go to  Data Scientist Workbench  and click the  My Notebooks  menu.   Paste the link in the text field at the top right corner of the page.\n     \n     \n     \n        Hit  Enter  to import the file or notebook.", 
            "title": "Importing Data and Notebooks"
        }, 
        {
            "location": "/howtos/load-data-dsw/", 
            "text": "To data into your Data Scientist Workbench, all you have to do is:\n\n\n\n\nGo to \nData Scientist Workbench\n and click the \nMy Notebooks\n menu.\n\n\nDrag the files you want to load from your computer and drop them on DSW.\n\n\n\n\nNote:\n There is no upload progress indication. If you're trying to upload a large file, it might take a few minutes for the upload to complete and the file show up in \"Recent Data\".", 
            "title": "Load Data into DSW"
        }, 
        {
            "location": "/howtos/install-libs/", 
            "text": "R\n\n\nUse \ninstall.packages()\n in a R notebook, as shown in the example below.\n\n\ninstall.packages(\nyaml\n, repos=\nhttp://cran.stat.ucla.edu\n)\n\n\n\n\nPython\n\n\nOpen a Python notebook and use \npip\n to install Python packages, as shown below.\n\n\n!pip install vincent\n\n\n\n\nScala\n\n\nAdding new JARs is not officially supported at this time.", 
            "title": "Install Libraries"
        }, 
        {
            "location": "/howtos/install-libs/#r", 
            "text": "Use  install.packages()  in a R notebook, as shown in the example below.  install.packages( yaml , repos= http://cran.stat.ucla.edu )", 
            "title": "R"
        }, 
        {
            "location": "/howtos/install-libs/#python", 
            "text": "Open a Python notebook and use  pip  to install Python packages, as shown below.  !pip install vincent", 
            "title": "Python"
        }, 
        {
            "location": "/howtos/install-libs/#scala", 
            "text": "Adding new JARs is not officially supported at this time.", 
            "title": "Scala"
        }, 
        {
            "location": "/howtos/submit-code/", 
            "text": "We'll use GitHub\n\n\nEnsure your team is \nregistered\n!\n\n\n\n\n\n\nSet Up Git\n\n\n\n\n\n\nInitialize your team's repository by:\n\n\n\n\n\n\nCreating a new repository:\n\n\n  echo \"# \nREPOSITORY_NAME\n\" \n README.md\n  git init\n  git add README.md\n  git commit -m \"first commit\"\n  git remote add origin git@github.com:hacktheweather/\nREPOSITORY_NAME\n.git\n  git push -u origin master\n\n\n\n\n\n\n\nOr push an existing one:\n\n\n  git remote add origin git@github.com:hacktheweather/\nREPOSITORY_NAME\n.git\n  git push -u origin master\n\n\n\n\n\n\n\n\n\n\n\nDownload your team's notebooks from DSW (\n.ipynb\n) to your machine.\n  \n\n  \n\n  \n\n  \n\n\n\n\n\n\nCommit and push notebooks and sample data to GitHub.", 
            "title": "Submit your Code"
        }
    ]
}