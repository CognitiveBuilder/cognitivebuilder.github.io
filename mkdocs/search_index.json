{
    "docs": [
        {
            "location": "/", 
            "text": ".steps-title { float: left; width: 25%; margin-bottom: 20px; }\n.steps-title > p { font-weight: bold; font-size: 150%; }\n.steps-content { float: left; width: 74%; margin-bottom: 20px; }\n.clear { clear: both; }\n.center { text-align: center; }\n.social { text-align: center; }\n\n\n\n\nWelcome to Cognitive Builder Faire!\n\n\nOut next Cognitive Builder Faire is in Austin, TX on April 28th!\n\n\nRegister for free now!\n\n\nCognitive Builder Faire\n is an immersive experience for the data science community to learn new skills, tools and technologies.\n\n\nLearn\n\n\nTake the \nSpark Fundamentals\n course and the\n\nData Science Experience Tutorial\n\non Big Data University.\n\n\nRun Spark\n\n\nLogin into your \nData Science Experience\n\naccount to have a Spark runtime immediately available for you!", 
            "title": "First Steps"
        }, 
        {
            "location": "/#welcome-to-cognitivebuilder", 
            "text": "Out next Cognitive Builder Faire is in Austin, TX on April 28th!  Register for free now!  Cognitive Builder Faire  is an immersive experience for the data science community to learn new skills, tools and technologies.", 
            "title": "Welcome to Cognitive Builder Faire!"
        }, 
        {
            "location": "/#learn", 
            "text": "Take the  Spark Fundamentals  course and the Data Science Experience Tutorial \non Big Data University.", 
            "title": "Learn"
        }, 
        {
            "location": "/#run-spark", 
            "text": "Login into your  Data Science Experience \naccount to have a Spark runtime immediately available for you!", 
            "title": "Run Spark"
        }, 
        {
            "location": "/introduction/slack/", 
            "text": "Slack\n is an\nawesome platform for team communication and it's our tool of\nchoice for this hackathon. All the communication will flow\nthrough Slack!\n\n\nYou have been sent an invitation for this hackathon's\n\nSlack team\n.\nIn case you haven't received it, please find an organizer.\n\n\nYou can use Slack from your Web browser, but we\n\nstrongly recommend\n that you the native apps:\n\n\n\n\nMac OS\n\n\nWindows\n\n\niOS\n\n\nAndroid", 
            "title": "Slack"
        }, 
        {
            "location": "/introduction/resources/", 
            "text": "Free courses on \nBig Data University\n:\n\n\n\n\n\n\nSpark Fundamentals\n\n\n\n\n\n\nBig Data Fundamentals\n\n\n\n\n\n\nHadoop Fundamentals I\n\n\n\n\n\n\nMoving Data into Hadoop\n\n\n\n\n\n\nBig Data Analytics - Demos", 
            "title": "Resources"
        }, 
        {
            "location": "/introduction/sessions/", 
            "text": "Tokyo\n\n\n\n\n\n\n\n\n\u30bb\u30c3\u30b7\u30e7\u30f3\n\n\n\u8cc7\u6599\n\n\n\n\n\n\n\n\n\n\n\u30101-1\u3011\u3061\u3087\u3063\u3068\u7406\u89e3\u306b\u81ea\u4fe1\u304c\u306a\u3044\u306a\u000b\u3068\u3044\u3046\u7686\u3055\u307e\u306b\u8d08\u308bHadoop\uff0fSpark\u306e\u30ad\u30db\u30f3\n\n\n\u30b9\u30e9\u30a4\u30c9\n\n\n\n\n\n\n\u30101-2\u3011PySpark\u306b\u3088\u308b\u30b8\u30e7\u30d6\u3092\u3001\u3088\u308a\u901f\u304f\u3001\u3088\u308a\u30b9\u30b1\u30fc\u30e9\u30d6\u30eb\u306b\u5b9f\u884c\u3059\u308b\u305f\u3081\u306e\u6700\u5584\u306e\u65b9\u6cd5\n\n\n\u30b9\u30e9\u30a4\u30c9\n\n\n\n\n\n\n\u30101-3\u3011Spark\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u958b\u767a\u3068\u6d3b\u7528\u306e\u52d5\u5411\n\n\n\u30b9\u30e9\u30a4\u30c9\n\n\n\n\n\n\n\u30101-4\u3011Apache Spark\u3067Bluemix IoT\u306e\u30c7\u30fc\u30bf\u3092\u5206\u6790\u3059\u308b\n\n\n\u30b9\u30e9\u30a4\u30c9\n\n\n\n\n\n\n\u30102-1\u3011\u5b9f\u8df5\u304b\u3089\u5b66\u3076\u3001\u6210\u529f\u3059\u308b\u30c7\u30fc\u30bf\u5206\u6790\u306e\u9032\u3081\u65b9\n\n\n\u30b9\u30e9\u30a4\u30c9\n\n\n\n\n\n\n\u30102-2\u3011Interpretability vs. predictivity\n\n\n\u975e\u516c\u958b\n\n\n\n\n\n\n\u30102-3\u3011\u300cR\u300d\u30a4\u30f3\u30c8\u30ed\u30c0\u30af\u30b7\u30e7\u30f3 \uff08\u5165\u9580\u30fb\u5b9f\u7fd2\u7de8\uff09\n\n\n\u30b9\u30e9\u30a4\u30c9\n\u30fb \n\u5b9f\u7fd2\n\n\n\n\n\n\n\u30102-4\u3011\u6750\u6599\u306b\u57fa\u3065\u3044\u3066\u6599\u7406\u306e\u4e88\u6e2c\uff1a\u30c7\u30fc\u30bf\u30b5\u30a4\u30a8\u30f3\u30b9\u65b9\u6cd5\u8ad6\uff08\u5b9f\u7fd2\u7de8\uff09\n\n\n\u30b9\u30e9\u30a4\u30c9\n\u30fb \n\u5b9f\u7fd2\n\n\n\n\n\n\n\u30103-1\u3011\u30a8\u30f3\u30b8\u30cb\u30a2\u304c\u59cb\u3081\u308b\u30c7\u30fc\u30bf\u30b5\u30a4\u30a8\u30f3\u30b9\n\n\n\u30b9\u30e9\u30a4\u30c9\n\u30fb \n\u5b9f\u7fd2\n\n\n\n\n\n\n\u30103-2\u3011\u4f4d\u7f6e\u00d7\u7bc4\u56f2\u00d7\u6642\u9593\u3067\u4eba\u3092\u77e5\u308b\u3002-\u884c\u52d5\u5206\u6790\u306e\u4e8b\u4f8b\u7d39\u4ecb-\n\n\n\u30b9\u30e9\u30a4\u30c9\n\n\n\n\n\n\n\u30103-3\u3011DMM.com\u306b\u304a\u3051\u308b\u30d3\u30c3\u30b0\u30c7\u30fc\u30bf\u51e6\u7406\u306e\u305f\u3081\u306eSQL\u6d3b\u7528\u8853\n\n\n\u30b9\u30e9\u30a4\u30c9\n\n\n\n\n\n\n\u30103-4\u3011\u30b9\u30bf\u30fc\u30c8\u30a2\u30c3\u30d7\u304c\u30c7\u30fc\u30bf\u30b5\u30a4\u30a8\u30f3\u30b9\u3092\u6b66\u5668\u306b\u5f37\u304f\u306a\u308b\n\n\nPrezi\n\n\n\n\n\n\n\u30104-1\u3011\u30c7\u30fc\u30bf\u30b5\u30a4\u30a8\u30f3\u30b9\u3068\u3057\u3066\u306e\u5fc3\u7406\u5b66\n\n\n\u30b9\u30e9\u30a4\u30c9\n\n\n\n\n\n\n\u30104-2\u3011IoT\u30c7\u30fc\u30bf\u306e\u5206\u6790\u3092\u306f\u3058\u3081\u308b\u306b\u306f\n\n\n\u30b9\u30e9\u30a4\u30c9\n\n\n\n\n\n\n\u30104-3\u3011Python\u3067\u59cb\u3081\u308b\u30c7\u30fc\u30bf\u5206\u6790\n\n\n\u30b9\u30e9\u30a4\u30c9\n\n\n\n\n\n\n\u30104-4\u3011IBM Bluemix\u3068\u30c7\u30fc\u30bf\u30b5\u30a4\u30a8\u30f3\u30b9\n\n\n\u30b9\u30e9\u30a4\u30c91\n\u30fb \n\u30b9\u30e9\u30a4\u30c92\n\n\n\n\n\n\nSansan\u30c7\u30fc\u30bf\u30b5\u30a4\u30a8\u30f3\u30b9\u30b3\u30f3\u30da\u300c\u4eba\u5de5\u77e5\u80fd\u306f\u540d\u523a\u3092\u3069\u3053\u307e\u3067\u89e3\u8aad\u3067\u304d\u308b\u306e\u304b\u300d\n\n\n\u8a73\u7d30\n\n\n\n\n\n\nMeetup: Big Data University - \u6771\u4eac\n\n\n\u8a73\u7d30\n\n\n\n\n\n\nBig Data University\n\n\n\u767b\u9332\n\n\n\n\n\n\nData Science Experience\n\n\n\u767b\u9332\n\n\n\n\n\n\n\n\nAustin\n\n\n\n\n\n\n\n\nSession\n\n\nMaterials\n\n\n\n\n\n\n\n\n\n\nApache SystemML: Declarative Machine Learning at Scale\n\n\nSlides\n\n\n\n\n\n\nCreating data pipelines with Luigi\n\n\nSlides\n\n\n\n\n\n\nDelivering Actionable Insights with Infrastructure Analytics\n\n\nSlides\n\n\n\n\n\n\nDistillation: Lessons from Design (and Bourbon) for Data and Decision Making\n\n\nSlides\n\n\n\n\n\n\nI KNOW (where) YOU (live)\n\n\nSlides\n\n\n\n\n\n\nIntro to Developing Dockerized Data Apps\n\n\nSlides\n\n\n\n\n\n\nIntro to Python for Data Science\n\n\nSlides\n\n\n\n\n\n\nPractical Data Engineering Techniques in Data Science\n\n\nSlides\n\n\n\n\n\n\n\n\nSeattle\n\n\n\n\n\n\n\n\nSession\n\n\nMaterials\n\n\n\n\n\n\n\n\n\n\nBuilding Scalable Data Pipelines\n\n\nSlides\n\n\n\n\n\n\nData to Action with IBM Bluemix\n\n\nSlides\n\n\n\n\n\n\nData Processing in Data Science\n\n\nSlides\n\n\n\n\n\n\nEssential Economics for Data Scientists\n\n\nSlides\n\n\n\n\n\n\nFeature Engineering for Predictive Modeling\n\n\nSlides\n\n\n\n\n\n\nIntro to Anaconda Cluster for Scientific Workflows\n\n\nSlides\n\n\n\n\n\n\nIntro to IBM Cloud Data Services and Apache Spark\n\n\nSlides\n\n\n\n\n\n\nIntro to Python for Data Analysis\n\n\nSlides\n\n\n\n\n\n\nInvestigating Data Scientists\n\n\nSlides\n\n\n\n\n\n\nMathematics for Data Science\n\n\nSlides\n\n\n\n\n\n\nSemantic Analysis of Natural Language with Python\n\n\nCode\n\n\n\n\n\n\nSpark and Scala: Coevolving Eco Systems for Data\n\n\nSlides\n\n\n\n\n\n\nStreaming Telematics Solution for Vehicle Failures\n\n\nSlides\n\n\n\n\n\n\nTune Up Your Data Science Process\n\n\nSlides\n\n\n\n\n\n\nWord2Vec with Twitter Data\n\n\nSlides\n\n\n\n\n\n\n\n\nSan Francisco\n\n\n\n\n\n\n\n\nSession\n\n\nMaterials\n\n\n\n\n\n\n\n\n\n\nCaltrain Rider: A Complete Data Product\n\n\nCode\n\n\n\n\n\n\nWhos in the News: Build a Quality web app with minimal code\n\n\nCode\n\n\n\n\n\n\nBuilding a Word2Vec Model with Twitter Data\n\n\nCode\n\n\n\n\n\n\nSpark Streaming application with Twitter and Watson\n\n\nCode\n\n\n\n\n\n\nMurv Part 1: Introduction to Muvr and lab around wearable and mobile\n\n\nCode\n\n\n\n\n\n\nCustomer Relationship Prediction with Machine Learning Ensembles\n\n\nCode\n\n\n\n\n\n\nMurv Part 2: Finish Wearable and mobile lab and move into a lab on training a model\n\n\nCode\n\n\n\n\n\n\nMurv Part 3: Final lab on paralleling computation and conclusion\n\n\nCode\n\n\n\n\n\n\nNLP Enriched Product Review\n\n\nCode\n\n\n\n\n\n\nSearch by Selfie: a Spark Facial Recognition Algorithm\n\n\nCode", 
            "title": "Session Materials"
        }, 
        {
            "location": "/introduction/sessions/#tokyo", 
            "text": "\u30bb\u30c3\u30b7\u30e7\u30f3  \u8cc7\u6599      \u30101-1\u3011\u3061\u3087\u3063\u3068\u7406\u89e3\u306b\u81ea\u4fe1\u304c\u306a\u3044\u306a\u000b\u3068\u3044\u3046\u7686\u3055\u307e\u306b\u8d08\u308bHadoop\uff0fSpark\u306e\u30ad\u30db\u30f3  \u30b9\u30e9\u30a4\u30c9    \u30101-2\u3011PySpark\u306b\u3088\u308b\u30b8\u30e7\u30d6\u3092\u3001\u3088\u308a\u901f\u304f\u3001\u3088\u308a\u30b9\u30b1\u30fc\u30e9\u30d6\u30eb\u306b\u5b9f\u884c\u3059\u308b\u305f\u3081\u306e\u6700\u5584\u306e\u65b9\u6cd5  \u30b9\u30e9\u30a4\u30c9    \u30101-3\u3011Spark\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u958b\u767a\u3068\u6d3b\u7528\u306e\u52d5\u5411  \u30b9\u30e9\u30a4\u30c9    \u30101-4\u3011Apache Spark\u3067Bluemix IoT\u306e\u30c7\u30fc\u30bf\u3092\u5206\u6790\u3059\u308b  \u30b9\u30e9\u30a4\u30c9    \u30102-1\u3011\u5b9f\u8df5\u304b\u3089\u5b66\u3076\u3001\u6210\u529f\u3059\u308b\u30c7\u30fc\u30bf\u5206\u6790\u306e\u9032\u3081\u65b9  \u30b9\u30e9\u30a4\u30c9    \u30102-2\u3011Interpretability vs. predictivity  \u975e\u516c\u958b    \u30102-3\u3011\u300cR\u300d\u30a4\u30f3\u30c8\u30ed\u30c0\u30af\u30b7\u30e7\u30f3 \uff08\u5165\u9580\u30fb\u5b9f\u7fd2\u7de8\uff09  \u30b9\u30e9\u30a4\u30c9 \u30fb  \u5b9f\u7fd2    \u30102-4\u3011\u6750\u6599\u306b\u57fa\u3065\u3044\u3066\u6599\u7406\u306e\u4e88\u6e2c\uff1a\u30c7\u30fc\u30bf\u30b5\u30a4\u30a8\u30f3\u30b9\u65b9\u6cd5\u8ad6\uff08\u5b9f\u7fd2\u7de8\uff09  \u30b9\u30e9\u30a4\u30c9 \u30fb  \u5b9f\u7fd2    \u30103-1\u3011\u30a8\u30f3\u30b8\u30cb\u30a2\u304c\u59cb\u3081\u308b\u30c7\u30fc\u30bf\u30b5\u30a4\u30a8\u30f3\u30b9  \u30b9\u30e9\u30a4\u30c9 \u30fb  \u5b9f\u7fd2    \u30103-2\u3011\u4f4d\u7f6e\u00d7\u7bc4\u56f2\u00d7\u6642\u9593\u3067\u4eba\u3092\u77e5\u308b\u3002-\u884c\u52d5\u5206\u6790\u306e\u4e8b\u4f8b\u7d39\u4ecb-  \u30b9\u30e9\u30a4\u30c9    \u30103-3\u3011DMM.com\u306b\u304a\u3051\u308b\u30d3\u30c3\u30b0\u30c7\u30fc\u30bf\u51e6\u7406\u306e\u305f\u3081\u306eSQL\u6d3b\u7528\u8853  \u30b9\u30e9\u30a4\u30c9    \u30103-4\u3011\u30b9\u30bf\u30fc\u30c8\u30a2\u30c3\u30d7\u304c\u30c7\u30fc\u30bf\u30b5\u30a4\u30a8\u30f3\u30b9\u3092\u6b66\u5668\u306b\u5f37\u304f\u306a\u308b  Prezi    \u30104-1\u3011\u30c7\u30fc\u30bf\u30b5\u30a4\u30a8\u30f3\u30b9\u3068\u3057\u3066\u306e\u5fc3\u7406\u5b66  \u30b9\u30e9\u30a4\u30c9    \u30104-2\u3011IoT\u30c7\u30fc\u30bf\u306e\u5206\u6790\u3092\u306f\u3058\u3081\u308b\u306b\u306f  \u30b9\u30e9\u30a4\u30c9    \u30104-3\u3011Python\u3067\u59cb\u3081\u308b\u30c7\u30fc\u30bf\u5206\u6790  \u30b9\u30e9\u30a4\u30c9    \u30104-4\u3011IBM Bluemix\u3068\u30c7\u30fc\u30bf\u30b5\u30a4\u30a8\u30f3\u30b9  \u30b9\u30e9\u30a4\u30c91 \u30fb  \u30b9\u30e9\u30a4\u30c92    Sansan\u30c7\u30fc\u30bf\u30b5\u30a4\u30a8\u30f3\u30b9\u30b3\u30f3\u30da\u300c\u4eba\u5de5\u77e5\u80fd\u306f\u540d\u523a\u3092\u3069\u3053\u307e\u3067\u89e3\u8aad\u3067\u304d\u308b\u306e\u304b\u300d  \u8a73\u7d30    Meetup: Big Data University - \u6771\u4eac  \u8a73\u7d30    Big Data University  \u767b\u9332    Data Science Experience  \u767b\u9332", 
            "title": "Tokyo"
        }, 
        {
            "location": "/introduction/sessions/#austin", 
            "text": "Session  Materials      Apache SystemML: Declarative Machine Learning at Scale  Slides    Creating data pipelines with Luigi  Slides    Delivering Actionable Insights with Infrastructure Analytics  Slides    Distillation: Lessons from Design (and Bourbon) for Data and Decision Making  Slides    I KNOW (where) YOU (live)  Slides    Intro to Developing Dockerized Data Apps  Slides    Intro to Python for Data Science  Slides    Practical Data Engineering Techniques in Data Science  Slides", 
            "title": "Austin"
        }, 
        {
            "location": "/introduction/sessions/#seattle", 
            "text": "Session  Materials      Building Scalable Data Pipelines  Slides    Data to Action with IBM Bluemix  Slides    Data Processing in Data Science  Slides    Essential Economics for Data Scientists  Slides    Feature Engineering for Predictive Modeling  Slides    Intro to Anaconda Cluster for Scientific Workflows  Slides    Intro to IBM Cloud Data Services and Apache Spark  Slides    Intro to Python for Data Analysis  Slides    Investigating Data Scientists  Slides    Mathematics for Data Science  Slides    Semantic Analysis of Natural Language with Python  Code    Spark and Scala: Coevolving Eco Systems for Data  Slides    Streaming Telematics Solution for Vehicle Failures  Slides    Tune Up Your Data Science Process  Slides    Word2Vec with Twitter Data  Slides", 
            "title": "Seattle"
        }, 
        {
            "location": "/introduction/sessions/#san-francisco", 
            "text": "Session  Materials      Caltrain Rider: A Complete Data Product  Code    Whos in the News: Build a Quality web app with minimal code  Code    Building a Word2Vec Model with Twitter Data  Code    Spark Streaming application with Twitter and Watson  Code    Murv Part 1: Introduction to Muvr and lab around wearable and mobile  Code    Customer Relationship Prediction with Machine Learning Ensembles  Code    Murv Part 2: Finish Wearable and mobile lab and move into a lab on training a model  Code    Murv Part 3: Final lab on paralleling computation and conclusion  Code    NLP Enriched Product Review  Code    Search by Selfie: a Spark Facial Recognition Algorithm  Code", 
            "title": "San Francisco"
        }, 
        {
            "location": "/challenges/seattle-day-1/", 
            "text": "Using \nData Science Experience\n, determine the top 5\nwinning teams and their average scores during the 2015-6 \nregular\n season. You\nshould also determine the best and worst teams for turnovers.\n\n\nJupyter\n\n\nGet the exercise and the data by importing the Jupyter notebook below.\n\n\nhttps://share.datascience.ibm.com/#/api/v1/workbench/10.114.214.147/shares/L00Ijjdc2x0y24m/Challenge_1.ipynb\n\n\nCopy the url above and\n\nimport it\n\nin your workbench by pasting it in the appropriate box.\n\n\n\n\n\n\n\n\nZeppelin\n\n\nIf you prefer, you can use Zeppelin instead of Jupyter.\n\n\n\n\nZeppelin notebook for Day 1 Challenge\n\n\n\n\nTo import into Zeppelin, click on \nImport Note\n on the Zeppelin front page.\n\n\nSolution\n\n\nOfficial solution for the Day 1 Challenge:\n\n\nhttps://share.datascience.ibm.com/#/api/v1/workbench/10.114.214.147/shares/eVtKpk0GwENtVuJ/SOLUTION_Challenge_1.ipynb\n\n\nWinning Entry\n\n\nHere is \nJayson Stemmler\n's\nwinning entry:\n\n\nhttps://share.datascience.ibm.com/#/api/v1/workbench/10.114.214.147/shares/SYvuu7cwJJgoJ8q/Challenge_1_SEA_JaysonStemmler.ipynb", 
            "title": "Seattle Day 1 Challenge"
        }, 
        {
            "location": "/challenges/seattle-day-1/#jupyter", 
            "text": "Get the exercise and the data by importing the Jupyter notebook below.  https://share.datascience.ibm.com/#/api/v1/workbench/10.114.214.147/shares/L00Ijjdc2x0y24m/Challenge_1.ipynb  Copy the url above and import it \nin your workbench by pasting it in the appropriate box.", 
            "title": "Jupyter"
        }, 
        {
            "location": "/challenges/seattle-day-1/#zeppelin", 
            "text": "If you prefer, you can use Zeppelin instead of Jupyter.   Zeppelin notebook for Day 1 Challenge   To import into Zeppelin, click on  Import Note  on the Zeppelin front page.", 
            "title": "Zeppelin"
        }, 
        {
            "location": "/challenges/seattle-day-1/#solution", 
            "text": "Official solution for the Day 1 Challenge:  https://share.datascience.ibm.com/#/api/v1/workbench/10.114.214.147/shares/eVtKpk0GwENtVuJ/SOLUTION_Challenge_1.ipynb", 
            "title": "Solution"
        }, 
        {
            "location": "/challenges/seattle-day-1/#winning-entry", 
            "text": "Here is  Jayson Stemmler 's\nwinning entry:  https://share.datascience.ibm.com/#/api/v1/workbench/10.114.214.147/shares/SYvuu7cwJJgoJ8q/Challenge_1_SEA_JaysonStemmler.ipynb", 
            "title": "Winning Entry"
        }, 
        {
            "location": "/challenges/seattle-day-2/", 
            "text": "We have a few tweets gathered the morning after the last Republican debate.\nDetermine the count of positive and negative tweets that contain the keyword\n\u201cTrump\u201d.\n\n\n\n\nHint:\n To get the solution we used the\n\nNatural Language Toolkit\n\n\n\n\nJupyter\n\n\nGet started with challenge in \nData Science Experience\n\nusing this Jupyter notebook:\n\n\nhttps://share.datascience.ibm.com/#/api/v1/workbench/10.114.214.147/shares/Zdc0xlFQbSbvKQm/Challenge_2.ipynb\n\n\nCopy the url above and\n\nimport it\n\nin your workbench by pasting it in the appropriate box.\n\n\n\n\n\n\n\n\nSolution\n\n\nOfficial solution for the Day 2 Challenge:\n\n\nhttps://share.datascience.ibm.com/#/api/v1/workbench/10.114.214.147/shares/S24DfpW9Z8zXzZC/SOLUTION_Challenge_2.ipynb\n\n\nWinning Entry\n\n\nHere is the winning entry:\n\n\nhttps://share.datascience.ibm.com/#/api/v1/workbench/10.114.214.147/shares/6hPnK3p8zY6zlMs/alexsher.ipynb", 
            "title": "Seattle Day 2 Challenge"
        }, 
        {
            "location": "/challenges/seattle-day-2/#jupyter", 
            "text": "Get started with challenge in  Data Science Experience \nusing this Jupyter notebook:  https://share.datascience.ibm.com/#/api/v1/workbench/10.114.214.147/shares/Zdc0xlFQbSbvKQm/Challenge_2.ipynb  Copy the url above and import it \nin your workbench by pasting it in the appropriate box.", 
            "title": "Jupyter"
        }, 
        {
            "location": "/challenges/seattle-day-2/#solution", 
            "text": "Official solution for the Day 2 Challenge:  https://share.datascience.ibm.com/#/api/v1/workbench/10.114.214.147/shares/S24DfpW9Z8zXzZC/SOLUTION_Challenge_2.ipynb", 
            "title": "Solution"
        }, 
        {
            "location": "/challenges/seattle-day-2/#winning-entry", 
            "text": "Here is the winning entry:  https://share.datascience.ibm.com/#/api/v1/workbench/10.114.214.147/shares/6hPnK3p8zY6zlMs/alexsher.ipynb", 
            "title": "Winning Entry"
        }, 
        {
            "location": "/challenges/seattle-day-3/", 
            "text": "Using data science techniques, identify the\ngreatest set of factors (age, sex, demographic, status, cabin location, etc.)\nthat had significant impact on survival probability for passengers of the\nTitanic.\n\n\nShow how you came to your conclusion.\n\n\nJupyter\n\n\nGet started with challenge in \nData Science Experience\n\nusing this Jupyter notebook:\n\n\nhttps://share.datascience.ibm.com/#/api/v1/workbench/10.114.214.147/shares/Lq860KgLkVZ0rKB/Challenge_3.ipynb\n\n\nCopy the url above and\n\nimport it\n\nin your workbench by pasting it in the appropriate box.", 
            "title": "Seattle Day 3 Challenge"
        }, 
        {
            "location": "/challenges/seattle-day-3/#jupyter", 
            "text": "Get started with challenge in  Data Science Experience \nusing this Jupyter notebook:  https://share.datascience.ibm.com/#/api/v1/workbench/10.114.214.147/shares/Lq860KgLkVZ0rKB/Challenge_3.ipynb  Copy the url above and import it \nin your workbench by pasting it in the appropriate box.", 
            "title": "Jupyter"
        }, 
        {
            "location": "/environment/dsx/", 
            "text": "Overview\n\n\nData Science Experience aims to be your one-stop shop for\ndata science tools. At this time, it includes Jupyter notebooks and Zeppelin notebooks enabled with Spark integration, as well as R Studio IDE and OpenRefine. You can use notebooks to develop and run data science projects, as well visualize, document and present your analysis.\n\n\n\n\n\n\n\n\nFor more information, take the \nData Science Experience Tutorial\n on Big Data University.\n\n\nRequesting your own Data Science Experience\n\n\nGo to \nData Science Experience\n and click the big blue button. After completing the registration, you will receive an e-mail with instructions.\n\n\nHello World\n\n\nTo get a feel of how the Data Scientist Notebooks work with Scala and Spark, follow the steps below to load a \"Hello World\" notebook along with its sample data.\n\n\n\n\n\n\n\nGo to \nData Science Experience\n and click the \nMy Notebooks\n menu.\n\n\n\n\nUse the search bar to import the following file and notebook.\n    \n\n    \n\n    \n\n    \n\n\n\n\n\n\nNotebook:\n  \nhttps://share.knowledgeanyhow.org/#/api/v1/workbench/10.114.214.68/shares/sHbSUP0luy1xE2q/Scala%20and%20Spark%20in%2015%20minutes.ipynb\n\n\n\n\n\n\nData:\n\nhttps://share.knowledgeanyhow.org/#/api/v1/workbench/10.114.214.68/shares/t9LwxWg0EkWKMYX/2015.csv\n\n\n\n\n\n\n\n\n\n\nFollow the notebook!\n    \n\n    \n\n    \n\n    \n\n\n\n\n\n\nFor more details on sharing data and notebooks, check \nthis guide\n.", 
            "title": "Data Science Experience"
        }, 
        {
            "location": "/environment/dsx/#overview", 
            "text": "Data Science Experience aims to be your one-stop shop for\ndata science tools. At this time, it includes Jupyter notebooks and Zeppelin notebooks enabled with Spark integration, as well as R Studio IDE and OpenRefine. You can use notebooks to develop and run data science projects, as well visualize, document and present your analysis.     For more information, take the  Data Science Experience Tutorial  on Big Data University.", 
            "title": "Overview"
        }, 
        {
            "location": "/environment/dsx/#requesting-your-own-data-scientist-workbench", 
            "text": "Go to  Data Science Experience  and click the big blue button. After completing the registration, you will receive an e-mail with instructions.", 
            "title": "Requesting your own Data Science Experience"
        }, 
        {
            "location": "/environment/dsx/#hello-world", 
            "text": "To get a feel of how the Data Scientist Notebooks work with Scala and Spark, follow the steps below to load a \"Hello World\" notebook along with its sample data.    Go to  Data Science Experience  and click the  My Notebooks  menu.   Use the search bar to import the following file and notebook.\n     \n     \n     \n        Notebook:\n   https://share.knowledgeanyhow.org/#/api/v1/workbench/10.114.214.68/shares/sHbSUP0luy1xE2q/Scala%20and%20Spark%20in%2015%20minutes.ipynb    Data: https://share.knowledgeanyhow.org/#/api/v1/workbench/10.114.214.68/shares/t9LwxWg0EkWKMYX/2015.csv      Follow the notebook!\n     \n     \n     \n        For more details on sharing data and notebooks, check  this guide .", 
            "title": "Hello World"
        }, 
        {
            "location": "/environment/download-sample-data/", 
            "text": "Sample Data - San Francisco\n\n\nWe are providing an example data set to get you started, but we encourage you to use use your own. You can download it in the link below.\n\n\nhttp://bit.ly/SFHackData\n\n\nNext, you'll probably want to extract the \nzip\n file and \nupload the \ncsv\n files to your workbench\n.", 
            "title": "Download Sample Data"
        }, 
        {
            "location": "/environment/download-sample-data/#sample-data-san-francisco", 
            "text": "We are providing an example data set to get you started, but we encourage you to use use your own. You can download it in the link below.  http://bit.ly/SFHackData  Next, you'll probably want to extract the  zip  file and  upload the  csv  files to your workbench .", 
            "title": "Sample Data - San Francisco"
        }, 
        {
            "location": "/howtos/analyzing-weather-data/", 
            "text": "Go to \nData Science Experience\n and click the \nMy Notebooks\n menu.\n\n\n\n\nUse the search bar to import the following notebooks.\n    \n\n    \n\n    \n\n    \n\n\n\n\n\n\nWeather Data Preparation:\n  \nhttps://share.knowledgeanyhow.org/#/api/v1/workbench/10.114.214.68/shares/L9ftHk00qCVG8qL/Weather%20Data%20Preparation%20v2.ipynb\n\n\n\n\n\n\nWeather Data Analysis and Visualization:\n  \nhttps://share.knowledgeanyhow.org/#/api/v1/workbench/10.114.214.68/shares/9tDhX5RIIQLIKcB/Weather%20Data%20Analysis%20Visualization%20v2.ipynb\n\n\n\n\n\n\n\n\n\n\nYou can get the \nAPI key\n \nhere\n.\n\n\n\n\n\n\nFollow the notebooks!\n    \n\n    \n\n    \n\n    \n\n\n\n\n\n\nFor more details on sharing data and notebooks, check \nthis guide\n.", 
            "title": "Analyzing Weather Data"
        }, 
        {
            "location": "/howtos/sharing-data-notebooks/", 
            "text": "Sharing data and notebooks can be very useful for team collaboration.\n\n\nExporting Data and Notebooks\n\n\n\n\nGo to \nData Science Experience\n and click the \nMy Notebooks\n menu.\n\n\nFind the file or notebook you want to share, and click the twistie (\n) to the left of it.\n\n\n\n\nClick the \nshare\n button (\n).\n    \n\n    \n\n    \n\n    \n\n\n\n\n\n\nClick the \nShow Link\n link to get the link to the shared notebook.\n\n\n\n\nSend this link to the person you're sharing the file or notebook with.\n\n\n\n\nImporting Data and Notebooks\n\n\n\n\nCopy the link of the file or notebook you want to import (from step 5 above).\n\n\nGo to \nData Science Experience\n and click the \nMy Notebooks\n menu.\n\n\n\n\nPaste the link in the text field at the top right corner of the page.\n    \n\n    \n\n    \n\n    \n\n\n\n\n\n\nHit \nEnter\n to import the file or notebook.", 
            "title": "Sharing Data and Notebooks"
        }, 
        {
            "location": "/howtos/sharing-data-notebooks/#exporting-data-and-notebooks", 
            "text": "Go to  Data Science Experience  and click the  My Notebooks  menu.  Find the file or notebook you want to share, and click the twistie ( ) to the left of it.   Click the  share  button ( ).\n     \n     \n     \n        Click the  Show Link  link to get the link to the shared notebook.   Send this link to the person you're sharing the file or notebook with.", 
            "title": "Exporting Data and Notebooks"
        }, 
        {
            "location": "/howtos/sharing-data-notebooks/#importing-data-and-notebooks", 
            "text": "Copy the link of the file or notebook you want to import (from step 5 above).  Go to  Data Science Experience  and click the  My Notebooks  menu.   Paste the link in the text field at the top right corner of the page.\n     \n     \n     \n        Hit  Enter  to import the file or notebook.", 
            "title": "Importing Data and Notebooks"
        }, 
        {
            "location": "/howtos/load-data-dsw/" class="deprecated_content", 
            "text": "To data into your Data Science Experience, all you have to do is:\n\n\n\n\nGo to \nData Science Experience\n and click the \nMy Notebooks\n menu.\n\n\nDrag the files you want to load from your computer and drop them on DSX.\n\n\n\n\nNote:\n There is no upload progress indication. If you're trying to upload a large file, it might take a few minutes for the upload to complete and the file show up in \"Recent Data\".", 
            "title": "Load Data into DSX"
        }, 
        {
            "location": "/howtos/install-libs/", 
            "text": "R\n\n\nUse \ninstall.packages()\n in a R notebook, as shown in the example below.\n\n\ninstall.packages(\nyaml\n, repos=\nhttp://cran.stat.ucla.edu\n)\n\n\n\n\nPython\n\n\nOpen a Python notebook and use \npip\n to install Python packages, as shown below.\n\n\n!pip install vincent\n\n\n\n\nScala\n\n\nAdding new JARs is not officially supported at this time.", 
            "title": "Install Libraries"
        }, 
        {
            "location": "/howtos/install-libs/#r", 
            "text": "Use  install.packages()  in a R notebook, as shown in the example below.  install.packages( yaml , repos= http://cran.stat.ucla.edu )", 
            "title": "R"
        }, 
        {
            "location": "/howtos/install-libs/#python", 
            "text": "Open a Python notebook and use  pip  to install Python packages, as shown below.  !pip install vincent", 
            "title": "Python"
        }, 
        {
            "location": "/howtos/install-libs/#scala", 
            "text": "Adding new JARs is not officially supported at this time.", 
            "title": "Scala"
        }, 
        {
            "location": "/howtos/submit-code/", 
            "text": "We'll use GitHub\n\n\nEnsure your team is \nregistered\n!\n\n\n\n\n\n\nSet Up Git\n\n\n\n\n\n\nInitialize your team's repository by:\n\n\n\n\n\n\nCreating a new repository:\n\n\n  echo \"# \nREPOSITORY_NAME\n\" \n README.md\n  git init\n  git add README.md\n  git commit -m \"first commit\"\n  git remote add origin git@github.com/cognitivebuilder\nREPOSITORY_NAME\n.git\n  git push -u origin master\n\n\n\n\n\n\n\nOr push an existing one:\n\n\n  git remote add origin git@github.com/cognitivebuilder\nREPOSITORY_NAME\n.git\n  git push -u origin master\n\n\n\n\n\n\n\n\n\n\n\nDownload your team's notebooks from DSX (\n.ipynb\n) to your machine.\n  \n\n  \n\n  \n\n  \n\n\n\n\n\n\nCommit and push notebooks and sample data to GitHub.", 
            "title": "Submit your Code"
        }
    ]
}
